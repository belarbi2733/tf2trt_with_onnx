{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow or Keras Model to TensorRT Using ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook show workflow of optimziing Tensorflow or Keras model with ONNX and TensorRR. Please refere to [this tutorial from Nvidia](https://developer.nvidia.com/blog/speeding-up-deep-learning-inference-using-tensorflow-onnx-and-tensorrt/) for more information\n",
    "\n",
    "The steps needed to optimzie Tensorflow/Keras model with ONNX and TensorRT:\n",
    "1. Convert the TensorFlow/Keras model to a .pb file.\n",
    "2. Convert the .pb file to the ONNX format.\n",
    "3. Create a TensorRT engine. \n",
    "4. Run inference from the TensorRT engine.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Convert the TensorFlow/Keras model to a .pb file.\n",
    "In this step will freeze the graph and save it as pb fromat\n",
    "kears_to_pb()\n",
    "take 3 arguments:\n",
    "    model: The Keras model.\n",
    "    output_filename: The output .pb file name.\n",
    "    output_node_names: The output nodes of the network. If None, then \n",
    "    the function gets the last layer name as the output node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from keras_to_pb  import keras_to_pb\n",
    "from keras.models import load_model\n",
    "\n",
    "#User defined values\n",
    "#Input file path\n",
    "MODEL_PATH = '/home/jetson-tx2/code/onnx/models/facenet_keras.h5'\n",
    "#output files paths\n",
    "PB_FILE_PATH = '/home/jetson-tx2/code/onnx/models/facenet_test.pb'\n",
    "ONNX_PATH = '/home/jetson-tx2/code/onnx/models/facenet_test.onnx'\n",
    "TRT_ENGINE_PATH = '/home/jetson-tx2/code/onnx/models/facenet_engine.plan'\n",
    "#End user defined values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(MODEL_PATH)\n",
    "input_name, output_node_names = keras_to_pb(model, OUTPUT_FILENAME, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Convert the .pb file to the ONNX format.\n",
    "\n",
    "Second step is to convert .pb file to ONNX fromat using `tf2onnx`. First install [tf2onnx](https://github.com/onnx/tensorflow-onnx).\n",
    "To install `tf2onnx`use this command `pip install -U tf2onnx`\n",
    "\n",
    "This may take more than 10 min to finish.  \n",
    "If command crash try to run it in terminal after closing Jupyter notebook and all other applications.  \n",
    "\n",
    "```\n",
    "python -m tf2onnx.convert --input /home/jetson-tx2/code/onnx/models/facenet.pb --inputs input_1:0[1,160,160,3] --outputs Bottleneck_BatchNorm/batchnorm_1/add_1:0 --output facenet.onnx\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-01 13:38:25.490624: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "WARNING:tensorflow:From /home/jetson-tx2/.virtualenvs/tf/lib/python3.6/site-packages/tf2onnx/verbose_logging.py:76: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "2020-10-01 13:38:31,023 - WARNING - From /home/jetson-tx2/.virtualenvs/tf/lib/python3.6/site-packages/tf2onnx/verbose_logging.py:76: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "2020-10-01 13:38:31.062681: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2020-10-01 13:38:31.067651: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-01 13:38:31.067812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1634] Found device 0 with properties: \n",
      "name: NVIDIA Tegra X2 major: 6 minor: 2 memoryClockRate(GHz): 1.3\n",
      "pciBusID: 0000:00:00.0\n",
      "2020-10-01 13:38:31.067873: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\n",
      "2020-10-01 13:38:31.071867: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2020-10-01 13:38:31.074446: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2020-10-01 13:38:31.075237: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2020-10-01 13:38:31.080047: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-10-01 13:38:31.083692: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-10-01 13:38:31.084438: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8\n",
      "2020-10-01 13:38:31.084729: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-01 13:38:31.085014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-01 13:38:31.085123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1762] Adding visible gpu devices: 0\n",
      "2020-10-01 13:38:31.108553: W tensorflow/core/platform/profile_utils/cpu_utils.cc:98] Failed to find bogomips in /proc/cpuinfo; cannot determine CPU frequency\n",
      "2020-10-01 13:38:31.109450: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x38e2a290 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-10-01 13:38:31.109543: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-10-01 13:38:31.213707: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-01 13:38:31.213985: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3b9847b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2020-10-01 13:38:31.214048: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA Tegra X2, Compute Capability 6.2\n",
      "2020-10-01 13:38:31.214386: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-01 13:38:31.214495: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1634] Found device 0 with properties: \n",
      "name: NVIDIA Tegra X2 major: 6 minor: 2 memoryClockRate(GHz): 1.3\n",
      "pciBusID: 0000:00:00.0\n",
      "2020-10-01 13:38:31.214564: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\n",
      "2020-10-01 13:38:31.214639: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2020-10-01 13:38:31.214690: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2020-10-01 13:38:31.214737: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2020-10-01 13:38:31.214777: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-10-01 13:38:31.214819: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-10-01 13:38:31.214859: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8\n",
      "2020-10-01 13:38:31.215025: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-01 13:38:31.215225: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-01 13:38:31.215294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1762] Adding visible gpu devices: 0\n",
      "2020-10-01 13:38:31.215366: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\n",
      "2020-10-01 13:38:33.694084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1175] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-10-01 13:38:33.695751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181]      0 \n",
      "2020-10-01 13:38:33.695831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1194] 0:   N \n",
      "2020-10-01 13:38:33.698670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-01 13:38:33.699345: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-01 13:38:33.699836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1320] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22 MB memory) -> physical GPU (device: 0, name: NVIDIA Tegra X2, pci bus id: 0000:00:00.0, compute capability: 6.2)\n",
      "2020-10-01 13:38:43.889505: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-01 13:38:43.889688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1634] Found device 0 with properties: \n",
      "name: NVIDIA Tegra X2 major: 6 minor: 2 memoryClockRate(GHz): 1.3\n",
      "pciBusID: 0000:00:00.0\n",
      "2020-10-01 13:38:43.889805: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\n",
      "2020-10-01 13:38:43.889884: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2020-10-01 13:38:43.889936: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2020-10-01 13:38:43.889987: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2020-10-01 13:38:43.890033: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-10-01 13:38:43.890075: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-10-01 13:38:43.890114: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8\n",
      "2020-10-01 13:38:43.890286: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-01 13:38:43.890482: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-01 13:38:43.890547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1762] Adding visible gpu devices: 0\n",
      "2020-10-01 13:38:43.890608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1175] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-10-01 13:38:43.890636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181]      0 \n",
      "2020-10-01 13:38:43.890657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1194] 0:   N \n",
      "2020-10-01 13:38:43.890834: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-01 13:38:43.891039: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-01 13:38:43.891130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1320] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22 MB memory) -> physical GPU (device: 0, name: NVIDIA Tegra X2, pci bus id: 0000:00:00.0, compute capability: 6.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-01 13:38:47.448815: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-01 13:38:47.449019: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2020-10-01 13:38:47.449349: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
      "2020-10-01 13:38:47.451374: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-01 13:38:47.451609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1634] Found device 0 with properties: \n",
      "name: NVIDIA Tegra X2 major: 6 minor: 2 memoryClockRate(GHz): 1.3\n",
      "pciBusID: 0000:00:00.0\n",
      "2020-10-01 13:38:47.451749: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\n",
      "2020-10-01 13:38:47.451887: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2020-10-01 13:38:47.452022: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2020-10-01 13:38:47.452193: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2020-10-01 13:38:47.452293: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-10-01 13:38:47.452368: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-10-01 13:38:47.452422: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8\n",
      "2020-10-01 13:38:47.452639: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-01 13:38:47.452892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-01 13:38:47.452976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1762] Adding visible gpu devices: 0\n",
      "2020-10-01 13:38:47.453043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1175] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-10-01 13:38:47.453076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181]      0 \n",
      "2020-10-01 13:38:47.453101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1194] 0:   N \n",
      "2020-10-01 13:38:47.453321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-01 13:38:47.453572: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-01 13:38:47.453692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1320] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22 MB memory) -> physical GPU (device: 0, name: NVIDIA Tegra X2, pci bus id: 0000:00:00.0, compute capability: 6.2)\n",
      "2020-10-01 13:38:52.816345: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:822] Optimization results for grappler item: graph_to_optimize\n",
      "2020-10-01 13:38:52.826193: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:824]   constant_folding: Graph size after: 1336 nodes (-496), 1387 edges (-497), time = 1478.18701ms.\n",
      "2020-10-01 13:38:52.826224: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:824]   function_optimizer: function_optimizer did nothing. time = 4.982ms.\n",
      "2020-10-01 13:38:52.826247: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:824]   constant_folding: Graph size after: 1336 nodes (0), 1387 edges (0), time = 269.893ms.\n",
      "2020-10-01 13:38:52.826269: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:824]   function_optimizer: function_optimizer did nothing. time = 8.766ms.\n",
      "2020-10-01 13:45:01.573106: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-01 13:45:01.573714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1634] Found device 0 with properties: \n",
      "name: NVIDIA Tegra X2 major: 6 minor: 2 memoryClockRate(GHz): 1.3\n",
      "pciBusID: 0000:00:00.0\n",
      "2020-10-01 13:45:01.583598: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\n",
      "2020-10-01 13:45:01.592169: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2020-10-01 13:45:01.592303: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2020-10-01 13:45:01.592365: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2020-10-01 13:45:01.592413: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-10-01 13:45:01.592456: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-10-01 13:45:01.592508: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8\n",
      "2020-10-01 13:45:01.592774: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-01 13:45:01.593036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-01 13:45:01.593113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1762] Adding visible gpu devices: 0\n",
      "2020-10-01 13:45:01.593226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1175] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-10-01 13:45:01.593255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181]      0 \n",
      "2020-10-01 13:45:01.593297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1194] 0:   N \n",
      "2020-10-01 13:45:01.593529: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-01 13:45:01.593744: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-01 13:45:01.593854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1320] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22 MB memory) -> physical GPU (device: 0, name: NVIDIA Tegra X2, pci bus id: 0000:00:00.0, compute capability: 6.2)\n",
      "2020-10-01 13:45:01,594 - INFO - Using tensorflow=1.15.3, onnx=1.7.0, tf2onnx=1.6.3/d4abc8\n",
      "2020-10-01 13:45:01,594 - INFO - Using opset <onnx, 8>\n",
      "2020-10-01 13:45:01,595 - INFO - Apply shape override:\n",
      "2020-10-01 13:45:01,595 - INFO - \tSet input_1:0 shape to [1, 160, 160, 3]\n",
      "2020-10-01 14:13:43,197 - INFO - Optimizing ONNX model\n",
      "2020-10-01 14:15:08,048 - INFO - After optimization: BatchNormalization -111 (111->0), Const -374 (644->270), Identity -3 (3->0), Transpose -490 (492->2)\n",
      "2020-10-01 14:15:09,585 - INFO - \n",
      "2020-10-01 14:15:09,585 - INFO - Successfully converted TensorFlow model /home/jetson-tx2/code/onnx/models/facenet_test.pb to ONNX\n",
      "2020-10-01 14:15:10,041 - INFO - ONNX model is saved at /home/jetson-tx2/code/onnx/models/facenet_test.onnx\n"
     ]
    }
   ],
   "source": [
    "!python -m tf2onnx.convert --input {PB_FILE_PATH} --inputs {input_name}:0[1,160,160,3] --outputs {output_node_names[0]}:0 --output {ONNX_FILE_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create a TensorRT engine from ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX model laoded...\n",
      "Creating engine from this onnx file,  /home/jetson-tx2/code/onnx/models/facenet_test.onnx\n",
      "TRT engine created and saved at,  /home/jetson-tx2/code/onnx/models/facenet_engine.plan\n"
     ]
    }
   ],
   "source": [
    "from onnx_to_trt import create_engine\n",
    "\n",
    "create_engine(ONNX_PATH, TRT_ENGINE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Run inference from the TensorRT engine\n",
    "\n",
    "The TensorRT engine runs inference in the following workflow: \n",
    "\n",
    "1. Allocate buffers for inputs and outputs in the GPU.\n",
    "2. Copy data from the host to the allocated input buffers in the GPU.\n",
    "3. Run inference in the GPU. \n",
    "4. Copy results from the GPU to the host. \n",
    "5. Reshape the results as necessary. \n",
    "\n",
    "Note: this is the code needed for inference. To test FacenetTRT with real image check script file `test_facenet_trt.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inference as inf\n",
    "\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.INTERNAL_ERROR)\n",
    "trt_runtime = trt.Runtime(TRT_LOGGER)\n",
    "\n",
    "engine = eng.load_engine(trt_runtime, engine_path)\n",
    "print('Engine loaded successfully...')\n",
    "\n",
    "h_input, d_input, h_output, d_output, stream = inf.allocate_buffers(engine, 1, trt.float32)\n",
    "out = inf.do_inference(engine, samples, h_input, d_input, h_output, d_output, stream, 1, 160, 160)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
