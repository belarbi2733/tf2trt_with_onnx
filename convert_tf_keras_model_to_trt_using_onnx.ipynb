{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow or Keras Model to TensorRT Using ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook show workflow of optimziing Tensorflow or Keras model with ONNX and TensorRT. Please refere to [this tutorial from Nvidia](https://developer.nvidia.com/blog/speeding-up-deep-learning-inference-using-tensorflow-onnx-and-tensorrt/) for more information\n",
    "\n",
    "The steps needed to optimzie Tensorflow/Keras model with ONNX and TensorRT:\n",
    "1. Convert the TensorFlow/Keras model to a .pb file.\n",
    "2. Convert the .pb file to the ONNX format.\n",
    "3. Create a TensorRT engine. \n",
    "4. Run inference from the TensorRT engine.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Convert the TensorFlow/Keras model to a .pb file.\n",
    "In this step will freeze the graph and save it as pb fromat\n",
    "kears_to_pb()\n",
    "take 3 arguments:\n",
    "    model: The Keras model.\n",
    "    output_filename: The output .pb file name.\n",
    "    output_node_names: The output nodes of the network. If None, then \n",
    "    the function gets the last layer name as the output node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from keras_to_pb_tf2  import keras_to_pb\n",
    "from keras.models import load_model\n",
    "\n",
    "#User defined values\n",
    "#Input file path\n",
    "MODEL_PATH = '/Users/riotu/Anas/tensorrt/tf2trt_with_onnx/facenet_keras_128.h5'\n",
    "#output files paths\n",
    "PB_FILE_PATH = '/Users/riotu/Anas/tensorrt/tf2trt_with_onnx/facenet_freezed.pb'\n",
    "ONNX_FILE_PATH = '/home/jetson-nx/tf2trt_wtih_onnx/facenet_onnx.onnx'\n",
    "TRT_ENGINE_PATH = '/home/jetson-nx/tf2trt_wtih_onnx/facenet_engine.plan'\n",
    "#End user defined values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/riotu/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Froze 490 variables.\n",
      "INFO:tensorflow:Converted 490 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "model = load_model(MODEL_PATH)\n",
    "input_name, output_node_names = keras_to_pb(model, PB_FILE_PATH, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Convert the .pb file to the ONNX format.\n",
    "\n",
    "Second step is to convert .pb file to ONNX fromat using `tf2onnx`. First install [tf2onnx](https://github.com/onnx/tensorflow-onnx).\n",
    "To install `tf2onnx`use this command `pip install -U tf2onnx`\n",
    "\n",
    "This may take more than 10 min to finish.  \n",
    "If command crash try to run it in terminal after closing Jupyter notebook and all other applications.  \n",
    "\n",
    "```\n",
    "python -m tf2onnx.convert --input /home/jetson-tx2/code/onnx/models/facenet.pb --inputs input_1:0[1,160,160,3] --outputs Bottleneck_BatchNorm/batchnorm_1/add_1:0 --output facenet.onnx\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U tf2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-07 11:09:37.047193: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "WARNING:tensorflow:From /home/jetson-nx/.virtualenvs/tf1/lib/python3.6/site-packages/tf2onnx/verbose_logging.py:76: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "2020-10-07 11:09:43,397 - WARNING - From /home/jetson-nx/.virtualenvs/tf1/lib/python3.6/site-packages/tf2onnx/verbose_logging.py:76: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "2020-10-07 11:09:43.461665: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2020-10-07 11:09:43.467704: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-07 11:09:43.467927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1634] Found device 0 with properties: \n",
      "name: Xavier major: 7 minor: 2 memoryClockRate(GHz): 1.109\n",
      "pciBusID: 0000:00:00.0\n",
      "2020-10-07 11:09:43.468006: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\n",
      "2020-10-07 11:09:43.474882: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2020-10-07 11:09:43.485458: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2020-10-07 11:09:43.486632: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2020-10-07 11:09:43.491115: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-10-07 11:09:43.494571: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-10-07 11:09:43.502549: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8\n",
      "2020-10-07 11:09:43.502908: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-07 11:09:43.503291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-07 11:09:43.503380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1762] Adding visible gpu devices: 0\n",
      "2020-10-07 11:09:43.556718: W tensorflow/core/platform/profile_utils/cpu_utils.cc:98] Failed to find bogomips in /proc/cpuinfo; cannot determine CPU frequency\n",
      "2020-10-07 11:09:43.557303: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1bb9a2d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-10-07 11:09:43.557376: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-10-07 11:09:43.810830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-07 11:09:43.811242: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1d24c830 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2020-10-07 11:09:43.811310: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Xavier, Compute Capability 7.2\n",
      "2020-10-07 11:09:43.811804: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-07 11:09:43.812182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1634] Found device 0 with properties: \n",
      "name: Xavier major: 7 minor: 2 memoryClockRate(GHz): 1.109\n",
      "pciBusID: 0000:00:00.0\n",
      "2020-10-07 11:09:43.812293: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\n",
      "2020-10-07 11:09:43.812381: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2020-10-07 11:09:43.812451: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2020-10-07 11:09:43.812515: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2020-10-07 11:09:43.812574: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-10-07 11:09:43.813187: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-10-07 11:09:43.813274: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8\n",
      "2020-10-07 11:09:43.813515: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-07 11:09:43.813752: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-07 11:09:43.813858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1762] Adding visible gpu devices: 0\n",
      "2020-10-07 11:09:43.813967: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\n",
      "2020-10-07 11:09:46.691274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1175] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-10-07 11:09:46.691403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181]      0 \n",
      "2020-10-07 11:09:46.691440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1194] 0:   N \n",
      "2020-10-07 11:09:46.691962: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-07 11:09:46.692319: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-07 11:09:46.692523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1320] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 225 MB memory) -> physical GPU (device: 0, name: Xavier, pci bus id: 0000:00:00.0, compute capability: 7.2)\n",
      "2020-10-07 11:09:56.607242: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-07 11:09:56.607657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1634] Found device 0 with properties: \n",
      "name: Xavier major: 7 minor: 2 memoryClockRate(GHz): 1.109\n",
      "pciBusID: 0000:00:00.0\n",
      "2020-10-07 11:09:56.607862: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\n",
      "2020-10-07 11:09:56.607988: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2020-10-07 11:09:56.608060: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2020-10-07 11:09:56.608112: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2020-10-07 11:09:56.608161: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-10-07 11:09:56.608232: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-10-07 11:09:56.608299: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8\n",
      "2020-10-07 11:09:56.608515: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-07 11:09:56.609322: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-07 11:09:56.609448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1762] Adding visible gpu devices: 0\n",
      "2020-10-07 11:09:56.609675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1175] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-10-07 11:09:56.609714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181]      0 \n",
      "2020-10-07 11:09:56.609754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1194] 0:   N \n",
      "2020-10-07 11:09:56.609985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-07 11:09:56.610285: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-07 11:09:56.610459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1320] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 225 MB memory) -> physical GPU (device: 0, name: Xavier, pci bus id: 0000:00:00.0, compute capability: 7.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-07 11:09:59.514260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-07 11:09:59.514482: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2020-10-07 11:09:59.514808: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
      "2020-10-07 11:09:59.517431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-07 11:09:59.517739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1634] Found device 0 with properties: \n",
      "name: Xavier major: 7 minor: 2 memoryClockRate(GHz): 1.109\n",
      "pciBusID: 0000:00:00.0\n",
      "2020-10-07 11:09:59.518001: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\n",
      "2020-10-07 11:09:59.518093: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2020-10-07 11:09:59.518195: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2020-10-07 11:09:59.518298: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2020-10-07 11:09:59.518408: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-10-07 11:09:59.518473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-10-07 11:09:59.518581: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8\n",
      "2020-10-07 11:09:59.518779: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-07 11:09:59.519036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-07 11:09:59.519131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1762] Adding visible gpu devices: 0\n",
      "2020-10-07 11:09:59.519227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1175] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-10-07 11:09:59.519314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181]      0 \n",
      "2020-10-07 11:09:59.519420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1194] 0:   N \n",
      "2020-10-07 11:09:59.519784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-07 11:09:59.520197: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-07 11:09:59.520365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1320] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 225 MB memory) -> physical GPU (device: 0, name: Xavier, pci bus id: 0000:00:00.0, compute capability: 7.2)\n",
      "2020-10-07 11:10:06.462685: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:822] Optimization results for grappler item: graph_to_optimize\n",
      "2020-10-07 11:10:06.475872: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:824]   constant_folding: Graph size after: 1336 nodes (-496), 1387 edges (-497), time = 2096.10205ms.\n",
      "2020-10-07 11:10:06.475992: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:824]   function_optimizer: function_optimizer did nothing. time = 5.645ms.\n",
      "2020-10-07 11:10:06.476075: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:824]   constant_folding: Graph size after: 1336 nodes (0), 1387 edges (0), time = 224.885ms.\n",
      "2020-10-07 11:10:06.476216: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:824]   function_optimizer: function_optimizer did nothing. time = 4.945ms.\n",
      "2020-10-07 11:14:50.686312: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-07 11:14:50.699663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1634] Found device 0 with properties: \n",
      "name: Xavier major: 7 minor: 2 memoryClockRate(GHz): 1.109\n",
      "pciBusID: 0000:00:00.0\n",
      "2020-10-07 11:14:50.894433: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\n",
      "2020-10-07 11:14:50.988692: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2020-10-07 11:14:51.027051: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2020-10-07 11:14:51.050448: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2020-10-07 11:14:51.073983: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-10-07 11:14:51.097456: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-10-07 11:14:51.142422: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8\n",
      "2020-10-07 11:14:51.142814: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-07 11:14:51.143516: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-07 11:14:51.143654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1762] Adding visible gpu devices: 0\n",
      "2020-10-07 11:14:51.148551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1175] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-10-07 11:14:51.149911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181]      0 \n",
      "2020-10-07 11:14:51.149987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1194] 0:   N \n",
      "2020-10-07 11:14:51.150607: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-07 11:14:51.150907: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n",
      "2020-10-07 11:14:51.153217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1320] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 225 MB memory) -> physical GPU (device: 0, name: Xavier, pci bus id: 0000:00:00.0, compute capability: 7.2)\n",
      "2020-10-07 11:14:51,178 - INFO - Using tensorflow=1.15.3, onnx=1.7.0, tf2onnx=1.6.3/d4abc8\n",
      "2020-10-07 11:14:51,179 - INFO - Using opset <onnx, 8>\n",
      "2020-10-07 11:14:51,185 - INFO - Apply shape override:\n",
      "2020-10-07 11:14:51,187 - INFO - \tSet input_1:0 shape to [1, 160, 160, 3]\n",
      "2020-10-07 11:36:26,694 - INFO - Optimizing ONNX model\n",
      "2020-10-07 11:37:40,663 - INFO - After optimization: BatchNormalization -111 (111->0), Const -374 (644->270), Identity -3 (3->0), Transpose -490 (492->2)\n",
      "2020-10-07 11:37:41,042 - INFO - \n",
      "2020-10-07 11:37:41,042 - INFO - Successfully converted TensorFlow model /home/jetson-nx/tf2trt_wtih_onnx/facenet_freezed.pb to ONNX\n",
      "2020-10-07 11:37:41,414 - INFO - ONNX model is saved at /home/jetson-nx/tf2trt_wtih_onnx/facenet_onnx.onnx\n"
     ]
    }
   ],
   "source": [
    "!python -m tf2onnx.convert --input {PB_FILE_PATH} --inputs {input_name}:0[1,160,160,3] --outputs {output_node_names[0]}:0 --output {ONNX_FILE_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create a TensorRT engine from ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX model laoded...\n",
      "Creating engine from this onnx file,  /home/jetson-nx/tf2trt_wtih_onnx/facenet_onnx.onnx\n",
      "TRT engine created and saved at,  /home/jetson-nx/tf2trt_wtih_onnx/facenet_engine.plan\n"
     ]
    }
   ],
   "source": [
    "from onnx_to_trt import create_engine\n",
    "\n",
    "create_engine(ONNX_PATH, TRT_ENGINE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Run inference from the TensorRT engine\n",
    "\n",
    "The TensorRT engine runs inference in the following workflow: \n",
    "\n",
    "1. Allocate buffers for inputs and outputs in the GPU.\n",
    "2. Copy data from the host to the allocated input buffers in the GPU.\n",
    "3. Run inference in the GPU. \n",
    "4. Copy results from the GPU to the host. \n",
    "5. Reshape the results as necessary. \n",
    "\n",
    "Note: this is the code needed for inference. To test FacenetTRT with real image check script file `test_facenet_trt.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inference as inf\n",
    "\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.INTERNAL_ERROR)\n",
    "trt_runtime = trt.Runtime(TRT_LOGGER)\n",
    "\n",
    "engine = eng.load_engine(trt_runtime, engine_path)\n",
    "print('Engine loaded successfully...')\n",
    "\n",
    "h_input, d_input, h_output, d_output, stream = inf.allocate_buffers(engine, 1, trt.float32)\n",
    "out = inf.do_inference(engine, samples, h_input, d_input, h_output, d_output, stream, 1, 160, 160)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
